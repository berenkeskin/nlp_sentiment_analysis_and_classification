{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis and Classification Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create machine learning models to predict sentiment score of the comments.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary modules:\n",
    "\n",
    "from textblob import TextBlob\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "\n",
    "import pandas, xgboost, numpy, textblob, string\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import layers, models, optimizers\n",
    "\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "data = pd.read_csv(\"train.tsv\",sep = \"\\t\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label comments with sentiment score 0, 1 as \"negative\" and ones with sentiment score 3, 4 as \"positive\":\n",
    "\n",
    "data[\"Sentiment\"].replace(0, value = \"negative\", inplace = True)\n",
    "data[\"Sentiment\"].replace(1, value = \"negative\", inplace = True)\n",
    "\n",
    "data[\"Sentiment\"].replace(3, value = \"positive\", inplace = True)\n",
    "data[\"Sentiment\"].replace(4, value = \"positive\", inplace = True)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rid of comments with sentiment score 2 for an exact binary system:\n",
    "\n",
    "data = data[(data.Sentiment == \"negative\") | (data.Sentiment == \"positive\")]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(\"Sentiment\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df[\"text\"] = data[\"Phrase\"]\n",
    "df[\"label\"] = data[\"Sentiment\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uppercase - lowercase conversion:\n",
    "df['text'] = df['text'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "\n",
    "# punctuations:\n",
    "df['text'] = df['text'].str.replace('[^\\w\\s]','')\n",
    "\n",
    "# numbers:\n",
    "df['text'] = df['text'].str.replace('\\d','')\n",
    "\n",
    "# stopwords:\n",
    "import nltk\n",
    "#nltk.download ('stopwords') \n",
    "from nltk.corpus import stopwords\n",
    "sw = stopwords.words('english')\n",
    "df['text'] = df['text'].apply(lambda x: \" \".join(x for x in x.split() if x not in sw))\n",
    "\n",
    "# deleting rare ones:\n",
    "sil = pd.Series(' '.join(df['text']).split()).value_counts()[-1000:]\n",
    "df['text'] = df['text'].apply(lambda x: \" \".join(x for x in x.split() if x not in sil))\n",
    "\n",
    "# lemmatization:\n",
    "from textblob import Word\n",
    "import nltk\n",
    "#nltk.download('wordnet')\n",
    "df['text'] = df['text'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Count Vectors\n",
    "* TF-IDF Vectors (words, characters, n-grams)\n",
    "* Word Embeddings\n",
    "\n",
    "TF(t) = (frequency of observing t in the document) / (total term count in the document) \n",
    "\n",
    "IDF(t) = log_e(total document count / document count that containing t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test - Train data:\n",
    "\n",
    "train_x, test_x, train_y, test_y = model_selection.train_test_split(df[\"text\"],\n",
    "                                                                   df[\"label\"], \n",
    "                                                                    random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert string to numeric for transform train_y and test_y:\n",
    "\n",
    "train_y = encoder.fit_transform(train_y)\n",
    "test_y = encoder.fit_transform(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform independent variables; train_x and test_x\n",
    "\n",
    "x_train_count = vectorizer.transform(train_x)\n",
    "x_test_count = vectorizer.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.get_feature_names()[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_count.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### wordlevel tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_word_vectorizer = TfidfVectorizer()\n",
    "tf_idf_word_vectorizer.fit(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform using tf-idf:\n",
    "\n",
    "x_train_tf_idf_word = tf_idf_word_vectorizer.transform(train_x)\n",
    "x_test_tf_idf_word = tf_idf_word_vectorizer.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_word_vectorizer.get_feature_names()[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tf_idf_word.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ngram level tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_ngram_vectorizer = TfidfVectorizer(ngram_range = (2,3))\n",
    "tf_idf_ngram_vectorizer.fit(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tf_idf_ngram = tf_idf_ngram_vectorizer.transform(train_x)\n",
    "x_test_tf_idf_ngram = tf_idf_ngram_vectorizer.transform(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### characters level tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_chars_vectorizer = TfidfVectorizer(analyzer = \"char\", ngram_range = (2,3))\n",
    "tf_idf_chars_vectorizer.fit(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tf_idf_chars = tf_idf_chars_vectorizer.transform(train_x)\n",
    "x_test_tf_idf_chars = tf_idf_chars_vectorizer.transform(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Classification with Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = linear_model.LogisticRegression()\n",
    "log_model = log.fit(x_train_count, train_y)\n",
    "accuracy = model_selection.cross_val_score(log_model, \n",
    "                                           x_test_count, \n",
    "                                           test_y, \n",
    "                                           cv = 10).mean()\n",
    "\n",
    "print(\"Count Vectors Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = linear_model.LogisticRegression()\n",
    "log_model = log.fit(x_train_tf_idf_word,train_y)\n",
    "accuracy = model_selection.cross_val_score(log_model, \n",
    "                                           x_test_tf_idf_word, \n",
    "                                           test_y, \n",
    "                                           cv = 10).mean()\n",
    "\n",
    "print(\"Word-Level TF-IDF Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = linear_model.LogisticRegression()\n",
    "log_model = log.fit(x_train_tf_idf_ngram,train_y)\n",
    "accuracy = model_selection.cross_val_score(log_model, \n",
    "                                           x_test_tf_idf_ngram, \n",
    "                                           test_y, \n",
    "                                           cv = 10).mean()\n",
    "\n",
    "print(\"N-GRAM TF-IDF Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = linear_model.LogisticRegression()\n",
    "log_model = log.fit(x_train_tf_idf_chars,train_y)\n",
    "accuracy = model_selection.cross_val_score(log_model, \n",
    "                                           x_test_tf_idf_chars, \n",
    "                                           test_y, \n",
    "                                           cv = 10).mean()\n",
    "\n",
    "print(\"CHARLEVEL Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = naive_bayes.MultinomialNB()\n",
    "nb_model = nb.fit(x_train_count,train_y)\n",
    "accuracy = model_selection.cross_val_score(nb_model, \n",
    "                                           x_test_count, \n",
    "                                           test_y, \n",
    "                                           cv = 10).mean()\n",
    "\n",
    "print(\"Count Vectors Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = naive_bayes.MultinomialNB()\n",
    "nb_model = nb.fit(x_train_tf_idf_word,train_y)\n",
    "accuracy = model_selection.cross_val_score(nb_model, \n",
    "                                           x_test_tf_idf_word, \n",
    "                                           test_y, \n",
    "                                           cv = 10).mean()\n",
    "\n",
    "print(\"Word-Level TF-IDF Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = naive_bayes.MultinomialNB()\n",
    "nb_model = nb.fit(x_train_tf_idf_ngram,train_y)\n",
    "accuracy = model_selection.cross_val_score(nb_model, \n",
    "                                           x_test_tf_idf_ngram, \n",
    "                                           test_y, \n",
    "                                           cv = 10).mean()\n",
    "\n",
    "print(\"N-GRAM TF-IDF Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = naive_bayes.MultinomialNB()\n",
    "nb_model = nb.fit(x_train_tf_idf_chars,train_y)\n",
    "accuracy = model_selection.cross_val_score(nb_model, \n",
    "                                           x_test_tf_idf_chars, \n",
    "                                           test_y, \n",
    "                                           cv = 10).mean()\n",
    "\n",
    "print(\"CHARLEVEL Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = ensemble.RandomForestClassifier()\n",
    "rf_model = rf.fit(x_train_count,train_y)\n",
    "accuracy = model_selection.cross_val_score(rf_model, \n",
    "                                           x_test_count, \n",
    "                                           test_y, \n",
    "                                           cv = 10).mean()\n",
    "\n",
    "print(\"Count Vectors Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = ensemble.RandomForestClassifier()\n",
    "rf_model = rf.fit(x_train_tf_idf_word,train_y)\n",
    "accuracy = model_selection.cross_val_score(rf_model, \n",
    "                                           x_test_tf_idf_word, \n",
    "                                           test_y, \n",
    "                                           cv = 10).mean()\n",
    "\n",
    "print(\"Word-Level TF-IDF Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = ensemble.RandomForestClassifier()\n",
    "rf_model = loj.fit(x_train_tf_idf_ngram,train_y)\n",
    "accuracy = model_selection.cross_val_score(rf_model, \n",
    "                                           x_test_tf_idf_ngram, \n",
    "                                           test_y, \n",
    "                                           cv = 10).mean()\n",
    "\n",
    "print(\"N-GRAM TF-IDF Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = ensemble.RandomForestClassifier()\n",
    "rf_model = loj.fit(x_train_tf_idf_chars,train_y)\n",
    "accuracy = model_selection.cross_val_score(rf_model, \n",
    "                                           x_test_tf_idf_chars, \n",
    "                                           test_y, \n",
    "                                           cv = 10).mean()\n",
    "\n",
    "print(\"CHARLEVEL Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = xgboost.XGBClassifier()\n",
    "xgb_model = xgb.fit(x_train_count,train_y)\n",
    "accuracy = model_selection.cross_val_score(xgb_model, \n",
    "                                           x_test_count, \n",
    "                                           test_y, \n",
    "                                           cv = 10).mean()\n",
    "\n",
    "print(\"Count Vectors Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = xgboost.XGBClassifier()\n",
    "xgb_model = xgb.fit(x_train_tf_idf_word,train_y)\n",
    "accuracy = model_selection.cross_val_score(xgb_model, \n",
    "                                           x_test_tf_idf_word, \n",
    "                                           test_y, \n",
    "                                           cv = 10).mean()\n",
    "\n",
    "print(\"Word-Level TF-IDF Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = xgboost.XGBClassifier()\n",
    "xgb_model = xgb.fit(x_train_tf_idf_ngram,train_y)\n",
    "accuracy = model_selection.cross_val_score(xgb_model, \n",
    "                                           x_test_tf_idf_ngram, \n",
    "                                           test_y, \n",
    "                                           cv = 10).mean()\n",
    "\n",
    "print(\"N-GRAM TF-IDF Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = xgboost.XGBClassifier()\n",
    "xgb_model = xgb.fit(x_train_tf_idf_chars,train_y)\n",
    "accuracy = model_selection.cross_val_score(xgb_model, \n",
    "                                           x_test_tf_idf_chars, \n",
    "                                           test_y, \n",
    "                                           cv = 10).mean()\n",
    "\n",
    "print(\"CHARLEVEL Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Choose a model; I choose logistic regression:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_comment = pd.Series(\"this film is very nice i like it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = CountVectorizer()\n",
    "v.fit(train_x)\n",
    "new_comment = v.transform(new_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_model.predict(new_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
